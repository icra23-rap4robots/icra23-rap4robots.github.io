<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Program | RAP4Robots 2023</title>
<meta name="generator" content="Jekyll v3.7.4" />
<meta property="og:title" content="Program" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Workshop on Efficient Representations, Abstractions, Priors for Robot Learning" />
<meta property="og:description" content="Workshop on Efficient Representations, Abstractions, Priors for Robot Learning" />
<link rel="canonical" href="https://mohitsharma0690.github.io//RAP4Robots/2021/program/" />
<meta property="og:url" content="https://mohitsharma0690.github.io//RAP4Robots/2021/program/" />
<meta property="og:site_name" content="RAP4Robots 2023" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@annargrs" />
<script type="application/ld+json">
{"@type":"WebPage","headline":"Program","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://mohitsharma0690.github.io//RAP4Robots/assets/img/lemonade-logo.png"}},"url":"https://mohitsharma0690.github.io//RAP4Robots/2021/program/","description":"Workshop on Efficient Representations, Abstractions, Priors for Robot Learning","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/RAP4Robots/assets/css/style.css?v=d77841d3fbc6d6e3ca2e7f5a791dc4f70ed64e62">
    <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->

  </head>
  <body>
    <div class="wrapper">
      <header>
        <!--h1><a href="">RAP4Robots 2023</a></h1-->
        <!--h1><a href="https://mohitsharma0690.github.io//RAP4Robots/">RAP4Robots 2023</a></h1-->


  <meta name="twitter:site" content="@annargrs">
  <meta name="twitter:title" content="Program">
  <meta name="twitter:description" content="">
  <meta name="twitter:url" content="">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content="https://mohitsharma0690.github.io//RAP4Robots/assets/img/lemonade-white.png">

  



        
          <img src="/RAP4Robots/assets/img/lemonade-logo.png" alt="Logo" />
        

        <p style="font-size: larger;"><b>Workshop on Efficient Representations, Abstractions, Priors for Robot Learning</b></p>
          <!--p><b>Workshop on Insights from Negative Results in NLP</b></p-->
          <br>ICRA 2023</br>
        </p>

        <!--p class="view"><a href="https://github.com/mohitsharma0690/RAP4Robots">View the Project on GitHub <small>mohitsharma0690/RAP4Robots</small></a></p-->
          <!-- <p class="view"><a href="/index">About</a></p> -->
          <p class="view"><a href="/RAP4Robots/">About</a></p>
        <!-- <p class="view"><a href="/2022/cfp">Call for papers</a></p> -->
        <p class="view"><a href="/RAP4Robots/2022/cfp">Call for papers</a></p>
        <!-- <p class="view"><a href="/2022/accepted">Accepted papers</a></p> -->
        <p class="view"><a href="/RAP4Robots/2022/accepted">Accepted papers</a></p>
        <!-- <p class="view"><a href="/2022/program">Program</a></p> -->
        <p class="view"><a href="/RAP4Robots/2022/program">Program</a></p>
     <!-- <p class="view"><a href="/2022/sponsors">Sponsors</a></p> -->
     <p class="view"><a href="/RAP4Robots/2022/sponsors">Sponsors</a></p>
        <!--p class="view"><a href="/papers">Insightful paper examples</a></p-->
        <!-- <p class="view"><a href="/2022/organization">Organization</a></p> -->
        <p class="view"><a href="/RAP4Robots/2022/organization">Organization</a></p>
    <!-- <p class="view"><a href="/2022/speakers">Invited Speakers</a></p> -->
    <p class="view"><a href="/RAP4Robots/2022/speakers">Invited Speakers</a></p>
    <!-- <p class="view"><a href="/2022/pc">Program Committee</a></p> -->
    <p class="view"><a href="/RAP4Robots/2022/pc">Program Committee</a></p>
        <!-- <p class="view"><a href="/2021">Insights 2021</a></p>
        <p class="view"><a href="/2020">Insights 2020</a></p> -->
        
      </header>
      <section>

      <h1 id="program"><span class="time">Program</span></h1>

<p>Insights 2021 will be a hybrid workshop. The poster sessions will be conducted online, in gather.town. The other sessions will have a mixture of virtual and on-site speakers and attendees.</p>

<p>Please see <a href="https://underline.io/events/192/sessions?eventSessionId=7857">the workshop page on underline</a> for the gather.town and zoom links.</p>

<p>All times are local time (Punta Cana, GMT-4).</p>

<p><span class="time">8:45–9:00</span> Opening remarks</p>

<p><span class="time">9:00–10:00</span> Invited talk: <a href="https://homepages.inf.ed.ac.uk/bonnie/">Bonnie Webber</a> (University of Edinburgh) <a href="https://www.youtube.com/watch?v=wrBvQznrzKU">[Video]</a></p>

<p><strong>The Reviewers and the Reviewed: Institutional Memory and Institutional Incentives</strong></p>
<blockquote>
  <p>Everyone has their own stories about unfair reviewers, misguided reviewers,  and reviewers who just don’t seem to get it. A Workshop on “Insights from  Negative Results” then seems just the place to reflect on who reviews are for, what purpose they serve for authors and reviewers, and what may be gained or lost from recent changes to conference reviewing.</p>
</blockquote>

<p><span class="time">10:00–11:15</span> Poster session 1</p>
<blockquote>
  <ul>
    <li><em>Two Heads are Better than One? Verification of Ensemble Effect in Neural Machine Translation</em> <a href="https://aclanthology.org/2021.insights-1.4/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39449-two-heads-are-better-than-onequestion-verification-of-ensemble-effect-in-neural-machine-translation">[Video]</a> <br /> Chanjun Park, Sungjin Park, Seolhwa Lee, Taesun Whang and Heuiseok Lim</li>
    <li><em>The Highs and Lows of Simple Lexical Domain Adaptation Approaches for Neural Machine Translation</em> <a href="https://aclanthology.org/2021.insights-1.12/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39457-the-highs-and-lows-of-simple-lexical-domain-adaptation-approaches-for-neural-machine-translation">[Video]</a> <br /> Nikolay Bogoychev and Pinzhen Chen</li>
    <li><em>Backtranslation in Neural Morphological Inflection</em> <a href="https://aclanthology.org/2021.insights-1.13/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39458-backtranslation-in-neural-morphological-inflection">[Video]</a> <br /> Ling Liu and Mans Hulden</li>
    <li><em>Does Commonsense help in detecting Sarcasm?</em> <a href="https://aclanthology.org/2021.insights-1.2/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39447-does-commonsense-help-in-detecting-sarcasmquestion">[Video]</a> <br /> Somnath Basu Roy Chowdhury and Snigdha Chaturvedi</li>
    <li><em>Finetuning Pretrained Transformers into Variational Autoencoders</em> <a href="https://aclanthology.org/2021.insights-1.5/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39450-finetuning-pretrained-transformers-into-variational-autoencoders">[Video]</a> <br /> Seongmin Park and Jihwa Lee</li>
    <li><em>Zero-Shot Cross-Lingual Transfer is a Hard Baseline to Beat in German Fine-Grained Entity Typing</em> <a href="https://aclanthology.org/2021.insights-1.7/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39452-zero-shot-cross-lingual-transfer-is-a-hard-baseline-to-beat-in-german-fine-grained-entity-typing">[Video]</a> <br /> Sabine Weber and Mark Steedman.</li>
    <li><em>Comparing Euclidean and Hyperbolic Embeddings on the WordNet Nouns Hypernymy Graph</em> <a href="https://aclanthology.org/2021.insights-1.8/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39453-comparing-euclidean-and-hyperbolic-embeddings-on-the-wordnet-nouns-hypernymy-graph">[Video]</a> <br /> Sameer Bansal and Adrian Benton.</li>
    <li><em>When does Further Pre-training MLM Help? An Empirical Study on Task-Oriented Dialog Pre-training</em> <a href="https://aclanthology.org/2021.insights-1.9/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39454-when-does-further-pre-training-mlm-helpquestion-an-empirical-study-on-task-oriented-dialog-pre-training">[Video]</a> <br /> Qi Zhu, Yuxian Gu, Lingxiao Luo, Bing Li, Cheng LI, Wei Peng, Minlie Huang and Xiaoyan Zhu</li>
    <li><em>On the Difficulty of Segmenting Words with Attention</em> <a href="https://aclanthology.org/2021.insights-1.11/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39456-on-the-difficulty-of-segmenting-words-with-attention">[Video]</a> <br /> Ramon Sanabria, Hao Tang and Sharon Goldwater</li>
    <li><em>Learning Data Augmentation Schedules for Natural Language Processing</em> <a href="https://aclanthology.org/2021.insights-1.14/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39459-learning-data-augmentation-schedules-for-natural-language-processing">[Video]</a> <br /> Daphné Chopard, Matthias S. Treder and Irena Spasić</li>
    <li><em>Investigating the Effect of Natural Language Explanations on Out-of-Distribution Generalization in Fewshot NLI</em> <a href="https://aclanthology.org/2021.insights-1.17/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39462-investigating-the-effect-of-natural-language-explanations-on-out-of-distribution-generalization-in-few-shot-nli">[Video]</a> <br /> Yangqiaoyu Zhou and Chenhao Tan</li>
    <li><em>Active Learning for Argument Strength Estimation</em> <a href="https://aclanthology.org/2021.insights-1.20/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39465-active-learning-for-argument-strength-estimation">[Video]</a> <br /> Nataliia Kees, Michael Fromm, Evgeniy Faerman and Thomas Seidl</li>
    <li><em>Temporal Adaptation of BERT and Performance on Downstream Document Classification: Insights from Social Media</em> <a href="https://aclanthology.org/2021.findings-emnlp.206/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/40586-temporal-adaptation-of-bert-and-performance-on-downstream-document-classification-insights-from-social-media">[Video]</a> <br /> Paul Röttger and Janet B. Pierrehumbert</li>
    <li><em>Does Vision-and-Language Pretraining Improve Lexical Grounding?</em> <a href="https://aclanthology.org/2021.findings-emnlp.370/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/40595-does-vision-and-language-pretraining-improve-lexical-groundingquestion">[Video]</a> <br /> Tian Yun, Chen Sun and Ellie Pavlick</li>
    <li><em>Recurrent Attention for the Transformer</em> <a href="https://aclanthology.org/2021.insights-1.10/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39455-recurrent-attention-for-the-transformer">[Video]</a> <br /> Jan Rosendahl, Christian Herold, Frithjof Petrick and Hermann Ney</li>
  </ul>
</blockquote>

<p><span class="time">11:15–11:30</span> Social break / coffee time</p>

<p><span class="time">11:30–12:30</span> Invited talk: <a href="http://zacklipton.com/">Zachary Lipton</a> (Carnegie Mellon University) <a href="https://www.youtube.com/watch?v=ldw33oNZaMs">[Video Part 1]</a> <a href="https://www.youtube.com/watch?v=WsXulRdr80w">[Video Part 2]</a> 
<br /></p>

<p><strong>When Cute Stories Belie a Messy Reality</strong></p>
<blockquote>
  <p>This talk will survey a broad set of negative results from our research over the last few years at ACMI lab, spanning (i) Reading Comprehension; (ii) Active Learning; (iii) Pretraining; (iv) Model Interpretation; (v) knowledge distillation; (vi) domain-adversarial neural networks; and (vii) Adversarial Question Answering. Some should have been seen from a mile away while others were genuinely surprising. The talk will touch upon some common themes, including (a) the blindspots that emerge when storytelling runs ahead of (or away from) the scientific process; (b) what constitutes a negative result worth publishing; and (c) positive outcomes from negative findings.</p>
</blockquote>

<p><span class="time">12:30–13:00</span> Thematic session 1 (oral presentations)</p>
<blockquote>
  <ul>
    <li><em>Two Heads are Better than One? Verification of Ensemble Effect in Neural Machine Translation</em> <a href="https://aclanthology.org/2021.insights-1.4/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39449-two-heads-are-better-than-onequestion-verification-of-ensemble-effect-in-neural-machine-translation">[Video]</a> <br /> Chanjun Park, Sungjin Park, Seolhwa Lee, Taesun Whang and Heuiseok Lim</li>
    <li><em>The Highs and Lows of Simple Lexical Domain Adaptation Approaches for Neural Machine Translation</em> <a href="https://aclanthology.org/2021.insights-1.12/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39457-the-highs-and-lows-of-simple-lexical-domain-adaptation-approaches-for-neural-machine-translation">[Video]</a> <br /> Nikolay Bogoychev and Pinzhen Chen</li>
    <li><em>Backtranslation in Neural Morphological Inflection</em> <a href="https://aclanthology.org/2021.insights-1.13/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39458-backtranslation-in-neural-morphological-inflection">[Video]</a> <br /> Ling Liu and Mans Hulden</li>
  </ul>
</blockquote>

<p><span class="time">13:00–14:00</span> Lunch break</p>

<p><span class="time">14:00–15:00</span> Invited talk: <a href="http://www.rctatman.com/">Rachael Tatman</a> (Rasa) <a href="https://www.youtube.com/watch?v=oHxRiTFtxOk">[Video]</a> 
<br /></p>

<p><strong>Chatbots can be good: What we learn from unhappy users</strong></p>
<blockquote>
  <p>It’s no secret that chatbots have a bad reputation: no one enjoys a cyclical, frustrating conversation when all you need is a quick answer to an urgent question. But chatbots can, in fact, be good. Having bad conversations can help us get there before they’re ever deployed
This talk will draw on both academic and industry knowledge to discuss problems like:</p>
  <ul>
    <li>What do users’ reactions to unsuccessful systems tell us about what successful systems should look like?</li>
    <li>Are we evaluating the right things… or the easy to measure things?</li>
    <li>Do we really have to look at user data? If so, when and how often?</li>
    <li>When, if ever, should we retire old methods?</li>
  </ul>
</blockquote>

<p><span class="time">15:00–16:15</span> Poster session 2</p>
<blockquote>
  <ul>
    <li><em>Corrected CBOW Performs as well as Skip-gram</em> <a href="https://aclanthology.org/2021.insights-1.1/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39446-corrected-cbow-performs-as-well-as-skip-gram">[Video]</a> <br /> Ozan ˙Irsoy, Adrian Benton and Karl Stratos</li>
    <li><em>An Investigation into the Contribution of Locally Aggregated Descriptors to Figurative Language Identification</em> <a href="https://aclanthology.org/2021.insights-1.15/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39460-an-investigation-into-the-contribution-of-locally-aggregated-descriptors-to-figurative-language-identification">[Video]</a> <br /> Sina Mahdipour Saravani, Ritwik Banerjee and Indrakshi Ray.</li>
    <li><em>Blindness to Modality Helps Entailment Graph Mining</em> <a href="https://aclanthology.org/2021.insights-1.16/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39461-blindness-to-modality-helps-entailment-graph-mining">[Video]</a> <br /> Liane Guillou, Sander Bijl de Vroe, Mark Johnson and Mark Steedman</li>
    <li><em>Generalization in NLI: Ways (Not) To Go Beyond Simple Heuristics</em> <a href="https://aclanthology.org/2021.insights-1.18/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39463-generalization-in-nli-ways-(not)-to-go-beyond-simple-heuristics">[Video]</a> <br /> Prajjwal Bhargava, Aleksandr Drozd and Anna Rogers</li>
    <li><em>Challenging the Semi-Supervised VAE Framework for Text Classification</em> <a href="https://aclanthology.org/2021.insights-1.19/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39464-challenging-the-semi-supervised-vae-framework-for-text-classification">[Video]</a> <br /> Ghazi Felhi, Joseph Le Roux and Djamé Seddah</li>
    <li><em>Investigating Numeracy of a Text-to-Text Transfer model</em> <a href="https://aclanthology.org/2021.findings-emnlp.265/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/40590-investigating-numeracy-of-a-text-to-text-transfer-model">[Video]</a> <br /> Kuntal Kumar Pal and Chitta Baral</li>
    <li><em>Do We Know What We Don’t Know? Studying Unanswerable Questions beyond SQuAD 2.0, Elior Sulem</em> <a href="https://aclanthology.org/2021.findings-emnlp.385/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/40594-do-we-know-what-we-don%E2%80%99t-knowquestion-studying-unanswerable-questions-beyond-squad-2.0">[Video]</a> <br /> Jamaal Hay and Dan Roth</li>
  </ul>
</blockquote>

<p><span class="time">16:15–16:30</span> Social break / coffee time</p>

<p><span class="time">16:30–17:00</span> Thematic session 2 (oral presentations)</p>
<blockquote>
  <ul>
    <li><em>BERT Cannot Align Characters</em> <a href="https://aclanthology.org/2021.insights-1.3/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39448-bert-cannot-align-characters">[Video]</a> <br /> Antonis Maronikolakis, Philipp Dufter and Hinrich Schütze</li>
    <li><em>Are BERTs Sensitive to Native Interference in L2 Production?</em> <a href="https://aclanthology.org/2021.insights-1.6/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/39451-are-berts-sensitive-to-native-interference-in-l2-productionquestion">[Video]</a> <br /> Zixin Tang, Prasenjit Mitra and David Reitter</li>
    <li><em>Is BERT a Cross-Disciplinary Knowledge Learner? A Surprising Finding of Pre-trained Models’ Transferability</em> <a href="https://aclanthology.org/2021.findings-emnlp.189/">[PDF]</a> <a href="https://underline.io/events/192/sessions/7857/lecture/40585-is-bert-a-cross-disciplinary-knowledge-learnerquestion-a-surprising-finding-of-pre-trained-models%E2%80%99-transferability">[Video]</a> <br /> Wei-Tsung Kao and Hung-yi Lee</li>
  </ul>
</blockquote>

<p><span class="time">17:00–18:00</span> Invited talk: <a href="https://homes.cs.washington.edu/~nasmith/">Noah Smith</a> (University of Washington / Allen Institute for AI) <a href="https://www.youtube.com/watch?v=98bTx9rMjUo">[Video]</a></p>

<h1 id="what-makes-a-result-negative"><strong>What Makes a Result Negative?</strong></h1>
<blockquote>
  <p>In this talk, I’ll discuss the frame of “negative results” that is used to describe outcomes in the research process, specifically in modern natural language processing.  I’ll link this frame to some assumptions that I think have been mostly harmful to research and researchers.  I’ll argue for a few first principles that can help us to design research projects in such a way that useful new information is likely to emerge, no matter what the experiments show.  Unfortunately, I can’t offer a foolproof method for avoiding “negative results,” but I do hope to move our field’s discourse to be better aligned with its broader goals, and offer some reminders about the incredible variety of ways to contribute to those goals.  Though this talk won’t spend much time highlighting the research findings of my mentees and collaborators, and the views expressed should only be taken as my own (not theirs), the worldview I discuss has developed through interactions with them, for which I am grateful.</p>
</blockquote>

<p><span class="time">18:00–18:15</span> Closing remarks</p>


      </section>
      <footer>
      
        
        <!--p>This project is maintained by <a href="https://github.com/mohitsharma0690">mohitsharma0690</a></p-->
        
        <!--p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p-->
      </footer>
    </div>
    <script src="/RAP4Robots/assets/js/scale.fix.js"></script>
    
  </body>
</html>
